# Enhancing Biomedical Context Reasoning in Language Models through Semantic Data Integration from Medical Knowledge Graphs: Application to Question Answering Systems
Large Language Models (LLMs) have demonstrated potential in handling natural language queries through their advanced text processing capabilities. Yet, in domain-specific areas such as biomedicine, relying solely on parametric knowledge, which lacks explainability and verifiability, is untrustworthy due to the specificity required in this domain. Architectures such as Retrieval-Augmented Generation (RAG) offer a solution by providing answers from LLMs based on a collection of verifiable document segments retrieved by the retrieval module. These segments often contain answers without explaining the medical concepts or their interconnections, leading to potential confusion and ambiguity in the LLM's responses. This paper proposes a novel pipeline to enhance the contextual understanding of question-answering (QA) systems by integrating biomedical concepts and their interrelationships. Our approach involves extracting biomedical entities, normalizing them using the Unified Medical Language System (UMLS), linking them to a Biomedical Knowledge Graph (BKG), and extracting relevant first-level relationships. By incorporating this enriched context into the RAG architecture, our results show a significant improvement in the system's ability to answer complex medical questions. Experimental results demonstrate a substantial enhancement in QA performance, surpassing state-of-the-art results on the BLURB benchmark by over 5\%. Additionally, we studied the continual learning behaviour of LLMs using our pipeline, mitigating the issue of catastrophic forgetting through a replay strategy. Our proposed pipeline offers a promising avenue for developing more accurate, reliable, and explainable biomedical QA systems.

![Global View Context Enhancement Pipeline](https://github.com/user-attachments/assets/02d89495-2866-4f3e-a875-46c8452cc3d3)


